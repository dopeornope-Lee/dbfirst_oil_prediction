{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dropout, Dense, LSTM\n",
    "from tensorflow.keras.layers import LSTM\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "matplotlib.rcParams['font.family'] ='Malgun Gothic'\n",
    "matplotlib.rcParams['axes.unicode_minus'] =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "SEQ_LEN = 14\n",
    "PRED_LEN = 1\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "DROPOUT = 0.2\n",
    "\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), 'model')\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "result_path = os.path.join(os.getcwd(), 'result')\n",
    "\n",
    "try:\n",
    "    os.makedirs(model_path)\n",
    "    os.makedirs(result_path)    \n",
    "\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 국제\n",
    "dataset1 = pd.read_csv(os.path.join(data_path, \"국제_원유가격.csv\"), parse_dates=['기간'], encoding='utf-8')\n",
    "dataset1 = dataset1.sort_values('기간')\n",
    "\n",
    "# 국내\n",
    "dataset2 = pd.read_csv(os.path.join(data_path, \"주유소_평균판매가격.csv\"), parse_dates=['구분'], encoding='utf-8')\n",
    "dataset2 = dataset2.sort_values('구분')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>기간</th>\n",
       "      <th>Dubai</th>\n",
       "      <th>Brent</th>\n",
       "      <th>WTI</th>\n",
       "      <th>고급휘발유</th>\n",
       "      <th>보통휘발유</th>\n",
       "      <th>자동차용경유</th>\n",
       "      <th>실내등유</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>103.66</td>\n",
       "      <td>111.31</td>\n",
       "      <td>113.79</td>\n",
       "      <td>1861.80</td>\n",
       "      <td>1681.33</td>\n",
       "      <td>1585.35</td>\n",
       "      <td>1159.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-04-16</td>\n",
       "      <td>105.16</td>\n",
       "      <td>112.66</td>\n",
       "      <td>114.93</td>\n",
       "      <td>1871.39</td>\n",
       "      <td>1692.15</td>\n",
       "      <td>1600.81</td>\n",
       "      <td>1168.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-04-17</td>\n",
       "      <td>106.39</td>\n",
       "      <td>112.43</td>\n",
       "      <td>114.86</td>\n",
       "      <td>1874.54</td>\n",
       "      <td>1686.56</td>\n",
       "      <td>1594.53</td>\n",
       "      <td>1174.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-04-18</td>\n",
       "      <td>105.83</td>\n",
       "      <td>113.92</td>\n",
       "      <td>116.69</td>\n",
       "      <td>1877.81</td>\n",
       "      <td>1689.68</td>\n",
       "      <td>1602.15</td>\n",
       "      <td>1179.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-04-21</td>\n",
       "      <td>107.96</td>\n",
       "      <td>114.43</td>\n",
       "      <td>117.48</td>\n",
       "      <td>1881.82</td>\n",
       "      <td>1695.54</td>\n",
       "      <td>1610.82</td>\n",
       "      <td>1191.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3637</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>106.65</td>\n",
       "      <td>114.24</td>\n",
       "      <td>114.20</td>\n",
       "      <td>2177.84</td>\n",
       "      <td>1958.73</td>\n",
       "      <td>1970.51</td>\n",
       "      <td>1481.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3638</th>\n",
       "      <td>2022-05-17</td>\n",
       "      <td>110.88</td>\n",
       "      <td>111.93</td>\n",
       "      <td>112.40</td>\n",
       "      <td>2183.42</td>\n",
       "      <td>1963.26</td>\n",
       "      <td>1976.49</td>\n",
       "      <td>1485.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>109.79</td>\n",
       "      <td>109.11</td>\n",
       "      <td>109.59</td>\n",
       "      <td>2185.95</td>\n",
       "      <td>1967.33</td>\n",
       "      <td>1981.61</td>\n",
       "      <td>1489.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>105.52</td>\n",
       "      <td>112.04</td>\n",
       "      <td>112.21</td>\n",
       "      <td>2191.74</td>\n",
       "      <td>1972.11</td>\n",
       "      <td>1986.76</td>\n",
       "      <td>1493.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>108.07</td>\n",
       "      <td>112.55</td>\n",
       "      <td>113.23</td>\n",
       "      <td>2196.10</td>\n",
       "      <td>1977.39</td>\n",
       "      <td>1990.99</td>\n",
       "      <td>1497.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3642 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             기간   Dubai   Brent     WTI    고급휘발유    보통휘발유   자동차용경유     실내등유\n",
       "0    2008-04-15  103.66  111.31  113.79  1861.80  1681.33  1585.35  1159.41\n",
       "1    2008-04-16  105.16  112.66  114.93  1871.39  1692.15  1600.81  1168.47\n",
       "2    2008-04-17  106.39  112.43  114.86  1874.54  1686.56  1594.53  1174.24\n",
       "3    2008-04-18  105.83  113.92  116.69  1877.81  1689.68  1602.15  1179.31\n",
       "4    2008-04-21  107.96  114.43  117.48  1881.82  1695.54  1610.82  1191.62\n",
       "...         ...     ...     ...     ...      ...      ...      ...      ...\n",
       "3637 2022-05-16  106.65  114.24  114.20  2177.84  1958.73  1970.51  1481.83\n",
       "3638 2022-05-17  110.88  111.93  112.40  2183.42  1963.26  1976.49  1485.38\n",
       "3639 2022-05-18  109.79  109.11  109.59  2185.95  1967.33  1981.61  1489.18\n",
       "3640 2022-05-19  105.52  112.04  112.21  2191.74  1972.11  1986.76  1493.57\n",
       "3641 2022-05-20  108.07  112.55  113.23  2196.10  1977.39  1990.99  1497.51\n",
       "\n",
       "[3642 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataset = pd.merge(left=dataset1, right=dataset2, left_on='기간', right_on='구분')\n",
    "del total_dataset['구분']\n",
    "total_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(data, seq_len, pred_len):\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(seq_len, len(data) - pred_len + 1):\n",
    "        x_train.append(data[i - seq_len: i, 0])\n",
    "        y_train.append(data[i + pred_len - 1: i + pred_len, 1])\n",
    "\n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "def preprocess(data_raw, seq_len, pred_len, train_split):\n",
    "\n",
    "    x_data, y_data = to_sequences(data_raw, seq_len, pred_len)\n",
    "    num_train = int(train_split * x_data.shape[0])\n",
    "\n",
    "    X_train = x_data[:num_train, :]\n",
    "    y_train = y_data[:num_train, :]\n",
    "\n",
    "    X_test = x_data[num_train:, :]\n",
    "    y_test = y_data[num_train:, :]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, BATCH_SIZE):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "\n",
    "    model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "    model.add(Dropout(rate=DROPOUT))\n",
    "\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        loss='mean_squared_error', \n",
    "        optimizer='adam'\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        epochs=50, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False,\n",
    "        validation_split=0.1\n",
    "    )\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def draw_plot_test(model, df, X_test, y_test, scaler):\n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    y_test_ = [y[0] for y in y_test]\n",
    "    y_hat = [y[0] for y in y_hat]\n",
    "\n",
    "    y_test_inverse = scaler.inverse_transform(pd.DataFrame(\n",
    "        {df.columns[0]: X_test[:,-1], \n",
    "        df.columns[1]: y_test_}\n",
    "        ))\n",
    "    y_hat_inverse = scaler.inverse_transform(pd.DataFrame(\n",
    "        {df.columns[0]: X_test[:,-1], \n",
    "        df.columns[1]: y_hat}\n",
    "        ))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "    ax1.plot(total_dataset.iloc[-len(X_test):, 0], y_test_inverse[:, 1], label=\"Actual Price (left)\", color='green')\n",
    "    ax1.plot(total_dataset.iloc[-len(X_test):, 0], y_hat_inverse[:, 1], label=\"Predicted Price (left)\", color='red')\n",
    "    ax1.set_ylabel(f'Price ({df.columns[1]}, won)')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(total_dataset.iloc[-len(X_test):, 0], y_test_inverse[:, 0], label=\"Brent Oil (right)\", color='blue')\n",
    "    ax2.set_ylabel(f'Price (Brent, $)')\n",
    "\n",
    "    plt.title(f'Oil Price ({df.columns[1]})')\n",
    "    plt.xlabel('Time [days]')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(result_path, f\"predict_test_{df.columns[1]}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot_total(model, df, X_total, y_total, scaler):\n",
    "    y_total_hat = model.predict(X_total)\n",
    "\n",
    "    y_total_ = [y[0] for y in y_total]\n",
    "    y_total_hat = [y[0] for y in y_total_hat]\n",
    "\n",
    "    y_test_inverse = scaler.inverse_transform(pd.DataFrame(\n",
    "        {df.columns[0]: X_total[:,-1], \n",
    "        df.columns[1]: y_total_}\n",
    "        ))\n",
    "    y_hat_inverse = scaler.inverse_transform(pd.DataFrame(\n",
    "        {df.columns[0]: X_total[:,-1], \n",
    "        df.columns[1]: y_total_hat}\n",
    "        ))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "    ax1.plot(total_dataset.iloc[-len(X_total):, 0], y_test_inverse[:, 1], label=\"Actual Price (left)\", color='green')\n",
    "    ax1.plot(total_dataset.iloc[-len(X_total):, 0], y_hat_inverse[:, 1], label=\"Predicted Price (left)\", color='red')\n",
    "    ax1.set_ylabel(f'Price ({df.columns[1]}, won)')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(total_dataset.iloc[-len(X_total):, 0], y_test_inverse[:, 0], label=\"Brent Oil (right)\", color='blue')\n",
    "    ax2.set_ylabel(f'Price (Brent, $)')\n",
    "\n",
    "    plt.title(f'Oil Price ({df.columns[1]})')\n",
    "    plt.xlabel('Time [days]')\n",
    "    ax1.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    plt.savefig(os.path.join(result_path, f\"predict_total_{df.columns[1]}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "194/194 [==============================] - 3s 8ms/step - loss: 0.0331 - val_loss: 0.0099\n",
      "Epoch 2/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0122 - val_loss: 0.0100\n",
      "Epoch 3/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 4/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0105 - val_loss: 0.0090\n",
      "Epoch 5/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0092 - val_loss: 0.0089\n",
      "Epoch 6/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 8/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0088\n",
      "Epoch 9/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0082 - val_loss: 0.0121\n",
      "Epoch 10/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 11/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 12/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0093\n",
      "Epoch 15/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0095\n",
      "Epoch 16/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0101\n",
      "Epoch 17/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0101\n",
      "Epoch 18/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0056 - val_loss: 0.0106\n",
      "Epoch 19/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0111\n",
      "Epoch 20/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0116\n",
      "Epoch 21/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0117\n",
      "Epoch 22/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0115\n",
      "Epoch 23/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0057 - val_loss: 0.0118\n",
      "Epoch 24/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0115\n",
      "Epoch 25/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0111\n",
      "Epoch 26/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0113\n",
      "Epoch 27/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0058 - val_loss: 0.0101\n",
      "Epoch 28/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0098\n",
      "Epoch 29/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 30/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0111\n",
      "Epoch 31/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0057 - val_loss: 0.0111\n",
      "Epoch 32/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0109\n",
      "Epoch 33/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0114\n",
      "Epoch 34/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0122\n",
      "Epoch 35/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0067 - val_loss: 0.0129\n",
      "Epoch 36/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 37/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0053 - val_loss: 0.0099\n",
      "Epoch 38/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0105\n",
      "Epoch 39/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0103\n",
      "Epoch 40/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0096\n",
      "Epoch 42/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0111\n",
      "Epoch 43/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 44/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0077 - val_loss: 0.0116\n",
      "Epoch 45/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0095\n",
      "Epoch 46/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0092\n",
      "Epoch 47/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0096\n",
      "Epoch 48/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 49/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 50/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0075 - val_loss: 0.0082\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "114/114 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0052\n",
      "Epoch 1/50\n",
      "194/194 [==============================] - 4s 10ms/step - loss: 0.0314 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0162 - val_loss: 0.0093\n",
      "Epoch 3/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0084\n",
      "Epoch 4/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0117 - val_loss: 0.0080\n",
      "Epoch 5/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0114 - val_loss: 0.0078\n",
      "Epoch 6/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 7/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0093 - val_loss: 0.0072\n",
      "Epoch 8/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 9/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 10/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0081 - val_loss: 0.0085\n",
      "Epoch 12/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 13/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 14/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 15/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0075 - val_loss: 0.0113\n",
      "Epoch 16/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0077 - val_loss: 0.0118\n",
      "Epoch 17/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0118\n",
      "Epoch 18/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0073 - val_loss: 0.0118\n",
      "Epoch 19/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0118\n",
      "Epoch 20/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0113\n",
      "Epoch 21/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 22/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0066 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0071 - val_loss: 0.0110\n",
      "Epoch 24/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 25/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0110\n",
      "Epoch 26/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0108\n",
      "Epoch 27/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 28/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 29/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0068 - val_loss: 0.0088\n",
      "Epoch 30/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0065 - val_loss: 0.0099\n",
      "Epoch 31/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0064 - val_loss: 0.0095\n",
      "Epoch 32/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.0063 - val_loss: 0.0074\n",
      "Epoch 33/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0061 - val_loss: 0.0083\n",
      "Epoch 34/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0064 - val_loss: 0.0069\n",
      "Epoch 35/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 36/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.0062 - val_loss: 0.0075\n",
      "Epoch 37/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 38/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 39/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 40/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 41/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 42/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 43/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 44/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 46/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0063 - val_loss: 0.0065\n",
      "Epoch 47/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 48/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 49/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 50/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "114/114 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.0407\n",
      "Epoch 1/50\n",
      "194/194 [==============================] - 3s 10ms/step - loss: 0.0338 - val_loss: 0.0107\n",
      "Epoch 2/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0092\n",
      "Epoch 3/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 4/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 5/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0078 - val_loss: 0.0091\n",
      "Epoch 6/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0070 - val_loss: 0.0088\n",
      "Epoch 7/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 8/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 9/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0055 - val_loss: 0.0085\n",
      "Epoch 10/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0089\n",
      "Epoch 11/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0056 - val_loss: 0.0094\n",
      "Epoch 12/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0052 - val_loss: 0.0084\n",
      "Epoch 13/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 14/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0052 - val_loss: 0.0086\n",
      "Epoch 15/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 17/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.0051 - val_loss: 0.0088\n",
      "Epoch 18/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0048 - val_loss: 0.0075\n",
      "Epoch 19/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 20/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 21/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0092\n",
      "Epoch 22/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0089\n",
      "Epoch 23/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 24/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 25/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0082\n",
      "Epoch 26/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0073\n",
      "Epoch 27/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0064\n",
      "Epoch 28/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 29/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 30/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0075\n",
      "Epoch 31/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 32/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 33/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 34/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 35/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 36/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 37/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0042 - val_loss: 0.0062\n",
      "Epoch 38/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 39/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 40/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 41/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 42/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 43/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0041 - val_loss: 0.0060\n",
      "Epoch 44/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 45/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 46/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0044 - val_loss: 0.0056\n",
      "Epoch 47/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 48/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 49/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 50/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0055\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "114/114 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0292\n",
      "Epoch 1/50\n",
      "194/194 [==============================] - 3s 8ms/step - loss: 0.0294 - val_loss: 0.0144\n",
      "Epoch 2/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0116 - val_loss: 0.0131\n",
      "Epoch 3/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 4/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 5/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 6/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 7/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0100 - val_loss: 0.0094\n",
      "Epoch 8/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 9/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 10/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0109 - val_loss: 0.0073\n",
      "Epoch 12/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 13/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0113 - val_loss: 0.0051\n",
      "Epoch 14/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0101 - val_loss: 0.0154\n",
      "Epoch 15/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0098 - val_loss: 0.0195\n",
      "Epoch 16/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0096 - val_loss: 0.0065\n",
      "Epoch 17/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0118 - val_loss: 0.0044\n",
      "Epoch 18/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0118 - val_loss: 0.0071\n",
      "Epoch 19/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0107 - val_loss: 0.0054\n",
      "Epoch 20/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0130 - val_loss: 0.0104\n",
      "Epoch 21/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 22/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0061\n",
      "Epoch 23/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0129 - val_loss: 0.0063\n",
      "Epoch 24/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0127 - val_loss: 0.0063\n",
      "Epoch 25/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0065\n",
      "Epoch 26/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0131 - val_loss: 0.0066\n",
      "Epoch 27/50\n",
      "194/194 [==============================] - 1s 6ms/step - loss: 0.0128 - val_loss: 0.0067\n",
      "Epoch 28/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0068\n",
      "Epoch 29/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0068\n",
      "Epoch 30/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0281\n",
      "Epoch 31/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0092 - val_loss: 0.0206\n",
      "Epoch 32/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 33/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0124 - val_loss: 0.0060\n",
      "Epoch 34/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0064\n",
      "Epoch 35/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0065\n",
      "Epoch 36/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0125 - val_loss: 0.0066\n",
      "Epoch 37/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 38/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 39/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0122 - val_loss: 0.0064\n",
      "Epoch 40/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0123 - val_loss: 0.0063\n",
      "Epoch 41/50\n",
      "194/194 [==============================] - 2s 8ms/step - loss: 0.0123 - val_loss: 0.0066\n",
      "Epoch 42/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0126 - val_loss: 0.0067\n",
      "Epoch 43/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0065\n",
      "Epoch 44/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0064\n",
      "Epoch 45/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0121 - val_loss: 0.0064\n",
      "Epoch 46/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 47/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0118 - val_loss: 0.0064\n",
      "Epoch 48/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0120 - val_loss: 0.0065\n",
      "Epoch 49/50\n",
      "194/194 [==============================] - 1s 7ms/step - loss: 0.0116 - val_loss: 0.0063\n",
      "Epoch 50/50\n",
      "194/194 [==============================] - 1s 8ms/step - loss: 0.0120 - val_loss: 0.0062\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "114/114 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0182\n"
     ]
    }
   ],
   "source": [
    "# total code for 4 different oils\n",
    "df1 = total_dataset.loc[:,['Brent', '고급휘발유']]\n",
    "df2 = total_dataset.loc[:,['Brent', '보통휘발유']]\n",
    "df3 = total_dataset.loc[:,['Brent', '자동차용경유']]\n",
    "df4 = total_dataset.loc[:,['Brent', '실내등유']]\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Oil_Name': ['고급휘발유', '보통휘발유', '자동차용경유', '실내등유'],\n",
    "})\n",
    "\n",
    "test_mse = []\n",
    "\n",
    "for i in range(4):\n",
    "    df = globals()[f\"df{i+1}\"]\n",
    "    oil_name = globals()[f\"df{i+1}\"].columns[1]\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(df)\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = preprocess(scaled_df, SEQ_LEN, PRED_LEN, train_split = 0.95)\n",
    "    trained_model, history = train_model(X_train, y_train, BATCH_SIZE)\n",
    "    trained_model.save(os.path.join(model_path, f\"LSTM_model_{oil_name}.h5\"))\n",
    "    \n",
    "    X_total = np.concatenate([X_train, X_test])\n",
    "    y_total = np.concatenate([y_train, y_test])\n",
    "    draw_plot_test(trained_model, df, X_test, y_test, scaler)\n",
    "    draw_plot_total(trained_model, df, X_total, y_total, scaler)\n",
    "\n",
    "    test_mse.append(trained_model.evaluate(X_test, y_test))\n",
    "\n",
    "result_df['test_mse'] = list(map(lambda x: round(x, 5), test_mse))\n",
    "result_df.to_csv(os.path.join(result_path, 'result.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48bd737276bd03fd170d194a949f636b40a5750d998da3916a08a7d77214e9fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tango')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
